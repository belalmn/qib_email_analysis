{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypff\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import HTML\n",
    "import re, os\n",
    "import email, datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session PID : 7416\n"
     ]
    }
   ],
   "source": [
    "print('Session PID :', os.getpid())\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "path = \"/home/belalm/email_analysis/data/raw/gmail_pst.pst\"  # PST file path\n",
    "opst = pypff.open(path)\n",
    "root = opst.get_root_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_object(obj):\n",
    "    number_of_sub_folders = obj.get_number_of_sub_folders()\n",
    "    number_of_entries = obj.get_number_of_entries()\n",
    "    number_of_sub_items = obj.get_number_of_sub_items() \n",
    "    number_of_sub_messages = obj.get_number_of_sub_messages()\n",
    "    number_of_record_sets = obj.get_number_of_record_sets()\n",
    "    entries = [obj.get_entry(i) for i in range(number_of_entries)]\n",
    "    folders = [obj.get_sub_folder(i) for i in range(number_of_sub_folders)]\n",
    "    data = {i.get_name(): i for i in folders} \n",
    "    final_dict = {\n",
    "        'number_of_sub_folders': number_of_sub_folders,\n",
    "        'number_of_entries': number_of_entries,\n",
    "        'number_of_sub_items': number_of_sub_items,\n",
    "        'number_of_sub_messages': number_of_sub_messages,\n",
    "        'number_of_record_sets': number_of_record_sets,\n",
    "        'data': data,\n",
    "        'entries': entries\n",
    "    }\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'pypff.folder' object has no attribute 'get_entry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m root_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_from_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m root_data\n",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m, in \u001b[0;36mget_data_from_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      5\u001b[0m number_of_sub_messages \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_number_of_sub_messages()\n\u001b[1;32m      6\u001b[0m number_of_record_sets \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_number_of_record_sets()\n\u001b[0;32m----> 7\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_entries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m folders \u001b[38;5;241m=\u001b[39m [obj\u001b[38;5;241m.\u001b[39mget_sub_folder(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_sub_folders)]\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m {i\u001b[38;5;241m.\u001b[39mget_name(): i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m folders} \n",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m number_of_sub_messages \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_number_of_sub_messages()\n\u001b[1;32m      6\u001b[0m number_of_record_sets \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_number_of_record_sets()\n\u001b[0;32m----> 7\u001b[0m entries \u001b[38;5;241m=\u001b[39m [\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_entry\u001b[49m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_entries)]\n\u001b[1;32m      8\u001b[0m folders \u001b[38;5;241m=\u001b[39m [obj\u001b[38;5;241m.\u001b[39mget_sub_folder(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_sub_folders)]\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m {i\u001b[38;5;241m.\u001b[39mget_name(): i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m folders} \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'pypff.folder' object has no attribute 'get_entry'"
     ]
    }
   ],
   "source": [
    "root_data = get_data_from_object(root)\n",
    "root_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_sub_folders': 8,\n",
       " 'number_of_entries': 4,\n",
       " 'number_of_sub_items': 8,\n",
       " 'number_of_sub_messages': 0,\n",
       " 'number_of_record_sets': 1,\n",
       " 'data': {'Deleted Items': <pypff.folder at 0x7f75375d8060>,\n",
       "  'Inbox': <pypff.folder at 0x7f7509f5bf90>,\n",
       "  'Outbox': <pypff.folder at 0x7f7509f5b3f0>,\n",
       "  'Sync Issues (This computer only)': <pypff.folder at 0x7f754c133720>,\n",
       "  '[Gmail]': <pypff.folder at 0x7f7509e10300>,\n",
       "  'Banking': <pypff.folder at 0x7f7509e11e60>,\n",
       "  'Notes': <pypff.folder at 0x7f7509e106c0>,\n",
       "  'Receipt': <pypff.folder at 0x7f7509e13540>}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outlook = root_data['data']['Top of Outlook data file']\n",
    "Outlook_Data = get_data_from_object(Outlook)\n",
    "Outlook_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_sub_folders': 0,\n",
       " 'number_of_entries': 20,\n",
       " 'number_of_sub_items': 5039,\n",
       " 'number_of_sub_messages': 5039,\n",
       " 'number_of_record_sets': 1,\n",
       " 'data': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inbox = Outlook_Data['data']['Inbox']\n",
    "Inbox_Data = get_data_from_object(Inbox)\n",
    "Inbox_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent = Outlook_Data['data']['Sent Items']\n",
    "Sent_Data = get_data_from_object(Sent)\n",
    "Sent_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayInhtml(index):\n",
    "\n",
    "    sample=Inbox.get_sub_message(index)\n",
    "\n",
    "    if sample.html_body:\n",
    "\n",
    "        html_string = sample.html_body.decode(\"utf-8\")\n",
    "\n",
    "        display(HTML(html_string))\n",
    "\n",
    "\n",
    "sample=Inbox.get_sub_message(576)\n",
    "\n",
    "print(sample.plain_text_body.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample.html_body:\n",
    "    html_string = sample.html_body.decode(\"utf-8\")\n",
    "    display(HTML(html_string))\n",
    "\n",
    "if sample.rtf_body:\n",
    "    rtf = sample.rtf_body.decode(\"utf-8\")\n",
    "    display(HTML(rtf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dir(sample):\n",
    "    if i.startswith('get'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert To Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMessage(message):\n",
    "    \"\"\"\n",
    "    The processMessage function processes multi-field messages to simplify collection of information\n",
    "    :param message: pypff.Message object\n",
    "    :return: A dictionary with message fields (values) and their data (keys)\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"id\": message.identifier,\n",
    "        \"subject\": message.subject,\n",
    "        \"sender_name\": message.sender_name,\n",
    "        \"header\": message.transport_headers,\n",
    "        \"body\": message.plain_text_body.decode('utf-8') if message.plain_text_body is not None else None,\n",
    "        \"creation_time\": message.creation_time,\n",
    "        \"submit_time\": message.client_submit_time,\n",
    "        \"delivery_time\": message.delivery_time,\n",
    "        \"attachment_count\": message.number_of_attachments,\n",
    "    }\n",
    "def checkForMessages(folder):\n",
    "    \"\"\"\n",
    "    The checkForMessages function reads folder messages if present and passes them to the report function\n",
    "    :param folder: pypff.Folder object\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    message_list = []\n",
    "    for message in tqdm(folder.sub_messages):\n",
    "        message_dict = processMessage(message)\n",
    "        message_list.append(message_dict)\n",
    "    df = pd.DataFrame(message_list)\n",
    "    df.insert(0, 'Folder', folder.name)\n",
    "    return df\n",
    "\n",
    "def is_valid_email(email):\n",
    "    \"\"\"\n",
    "    The is_valid_email function checks if an email address is valid\n",
    "    :param email: str\n",
    "    :return: Tuple (bool, str)\n",
    "    \"\"\"\n",
    "    if email is None:\n",
    "        return False, None\n",
    "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,5}$'\n",
    "    if re.match(pattern, email):\n",
    "        return True, email\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "def get_data_from_header(header):\n",
    "    \"\"\"\n",
    "    The get_data_from_header function extracts email addresses from the email header\n",
    "    :param header: str\n",
    "    :return: Tuple (str, str, str, str)\n",
    "    \"\"\"\n",
    "    if header is None:\n",
    "        return None, None, None, None\n",
    "    header = email.message_from_string(header)\n",
    "    From = header.get('From')\n",
    "    To = header.get('To')\n",
    "    CC = header.get('CC')\n",
    "    BCC = header.get('BCC')\n",
    "    return From, To, CC, BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for fol, folder in Outlook_Data['data'].items():\n",
    "    print(\"Folder Name : \", fol) # Inbox, Sent, etc.\n",
    "    temp = checkForMessages(folder)\n",
    "    df = df.append(temp)\n",
    "\n",
    "# df.id=df.id.astype('int')\n",
    "\n",
    "df['From'], df['To'], df['CC'], df['BCC'] = zip(*df.header.progress_apply(get_data_from_header))\n",
    "df.Folder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email.header import decode_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_external_flag(email):\n",
    "    if email is None:\n",
    "        return None\n",
    "    if 'qib.com.qa' in email.lower():\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_mail_flag(subject):\n",
    "    if subject is None:\n",
    "        return 'SUBJECT NOT FOUND'\n",
    "    if subject.upper().startswith('[MARKETING]'):\n",
    "        return \"MARKETING\"\n",
    "    if subject.upper().startswith('WARNING:'):\n",
    "        return \"WARNING\"\n",
    "    if subject.upper().startswith('RE:'):\n",
    "        return \"REPLY\"\n",
    "    if subject.upper().startswith('FW:'):\n",
    "        return \"FORWARDED\"\n",
    "    else:\n",
    "        return \"NA\"\n",
    "    \n",
    "# Function to check if an email is the first in a conversation\n",
    "def is_first_in_conversation(email_message):\n",
    "    flag = 0\n",
    "    subject = email_message.subject\n",
    "    email_message = email_message.header\n",
    "    if email_message is None:\n",
    "        return None\n",
    "    email_message = email.message_from_string(email_message)\n",
    "    message_id = email_message.get(\"Message-ID\")\n",
    "    in_reply_to = email_message.get(\"In-Reply-To\")  # \"Thread-Topic\"\n",
    "    # If Message-ID is present and In-Reply-To is missing or empty, it's likely the first email\n",
    "    if message_id and (not in_reply_to or in_reply_to.strip() == \"<>\"):\n",
    "        flag = 1\n",
    "    if subject is not None:\n",
    "        if flag and not subject.lower().startswith('re:'):\n",
    "            flag = 1\n",
    "        else:\n",
    "            flag = 0\n",
    "    return flag\n",
    "\n",
    "def is_english_or_arabic(text, check_arabic=True):\n",
    "    if text is None:\n",
    "        return False\n",
    "    try:\n",
    "        text = text.strip()\n",
    "        # Define regex patterns for English and Arabic characters\n",
    "        english_pattern = re.compile(r\"[A-Za-z]\")\n",
    "        arabic_pattern = re.compile(r\"[\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF]\")\n",
    "        # Check if the text contains English characters\n",
    "        if english_pattern.search(text) and not check_arabic:\n",
    "            return True\n",
    "        # Check if the text contains Arabic characters\n",
    "        if arabic_pattern.search(text) and check_arabic:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def extract_emails_and_domains(text):\n",
    "    if text is None:\n",
    "        return None, None\n",
    "    # Define a regex pattern for matching email addresses\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    # Use re.findall to find all email addresses in the text\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    # Extract domains from email addresses\n",
    "    domains = [re.search(r'@([A-Za-z0-9.-]+\\.[A-Za-z]{2,})', email).group(1) for email in emails]\n",
    "    return ''.join(emails), ''.join(domains).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FROM_EMAIL'], df['FROM_DOMAIN'] = zip(*df.From.progress_apply(extract_emails_and_domains))\n",
    "df['is_from_external'] = df.From.progress_apply(get_external_flag)\n",
    "df['is_first_in_conversation'] = df.progress_apply(is_first_in_conversation, axis=1)\n",
    "df['SUBJECT_FLAG'] = df.subject.progress_apply(get_mail_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_mail(email_text):\n",
    "    if email_text is None:\n",
    "        return None\n",
    "    email_text = re.sub(r'\\s+', ' ', email_text.split('From: ')[0])\n",
    "    email_text = email_text.strip()\n",
    "    return email_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_remove = [\n",
    "    \"CAUTION: This email originated from outside QIB. Do not click any links or open attachments unless you are sure of the safety of the contents.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mail(email_text, text_for_remove=None):\n",
    "    if email_text is None:\n",
    "        return None\n",
    "    try:\n",
    "        email_text = email_text.decode('utf-8')\n",
    "    except:\n",
    "        pass\n",
    "    pattern = re.compile(r'<.*?>')\n",
    "    # Use sub() method to replace matched tags with an empty string\n",
    "    email_text = re.sub(pattern, '', email_text)\n",
    "    if text_for_remove:\n",
    "        for i in text_for_remove:\n",
    "            email_text = email_text.replace(i, \"\")\n",
    "   \n",
    "    signature_pattern = r'--\\s*\\n.*$|\\n\\s*sent from[^\\n]*|\\n\\s*disclaimer[^\\n]*|\\n\\s*confidential[^\\n]*|\\n\\s*unsubscribe[^\\n]*'\n",
    "    # Remove the signature pattern from the email text\n",
    "    email_text = re.sub(signature_pattern, '', email_text, flags=re.IGNORECASE)\n",
    "    email_text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', email_text)\n",
    "    email_text = re.sub(r'\\S+@\\S+', '', email_text)\n",
    "    email_text = email_text.split('From: ')\n",
    "    email_text = [re.sub(r'\\s+', ' ', i) for i in email_text]\n",
    "    email_text = '\\n\\nFrom: '.join(email_text)\n",
    "    email_text = email_text.strip()\n",
    "    if text_for_remove:\n",
    "        for i in text_for_remove:\n",
    "            email_text = email_text.replace(i, \"\")\n",
    "    pattern = r'Sent from Yahoo Mail on Android <.*?>'\n",
    "    email_text = re.sub(pattern, '', email_text)\n",
    "    email_text = re.sub(r'-+|<.*?>', '', email_text)\n",
    "    email_text = re.sub(r'\\S+@\\S+', '', email_text)\n",
    "    email_text = re.sub(r'\\d', '', email_text)\n",
    "    footer_pattern = re.compile(r'Unsbcrib.*?Qatar Islamic Bank.*?Â©')\n",
    "    email_text = re.sub(footer_pattern, '', email_text)\n",
    "   \n",
    "    pattern = re.compile(re.escape('____') + r'.*')\n",
    "    # Remove text after the marker\n",
    "    email_text = re.sub(pattern, '', email_text)\n",
    "   \n",
    "    return email_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_text = sample.plain_text_body.decode('utf-8')\n",
    "print(email_text)\n",
    "print(clean_mail(email_text, text_for_remove))\n",
    "print(email_text)\n",
    "print(clean_mail(sample.plain_text_body.decode('utf-8'), text_for_remove))\n",
    "\n",
    "clean_mail(df.iloc[10].body, text_for_remove)\n",
    "\n",
    "df['clean_body'] = df.body.progress_apply(lambda x: clean_mail(x, text_for_remove))\n",
    "df['first_mail'] = df.clean_body.progress_apply(get_first_mail)\n",
    "\n",
    "df['is_english'] = df.first_mail.progress_apply(lambda x: is_english_or_arabic(x, False)).astype(int)\n",
    "df['is_arabic'] = df.first_mail.progress_apply(lambda x: is_english_or_arabic(x)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N - Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['XDG_CACHE_HOME']='Z:\\AI_Models'\n",
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "seed_keywords = None\n",
    "stop_words = ['hello', 'peace', 'best regards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(input_string, stop_words):\n",
    "    # Tokenize the input string into words\n",
    "    input_string = input_string.lower()\n",
    "    for word in stop_words:\n",
    "        input_string = input_string.replace(word.lower(), '')\n",
    "    words = input_string.split()\n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Reconstruct the string without stop words\n",
    "    output_string = ' '.join(filtered_words)\n",
    "    return output_string\n",
    "\n",
    "def get_ngram(text, n=1, top_n=100, stop_words=None):\n",
    "    try:\n",
    "        text = remove_stop_words(text, stop_words)\n",
    "        keywords = kw_model.extract_keywords(text,\n",
    "                                             keyphrase_ngram_range=(n, n),\n",
    "                                             stop_words=stop_words,\n",
    "                                             top_n=top_n, seed_keywords=seed_keywords)\n",
    "        return \",\".join([i[0] for i in keywords])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_nltk(text, n=1, flag=True):\n",
    "    out = None\n",
    "    try:\n",
    "        text = remove_stop_words(text, stop_words)\n",
    "        if text is None or len(text) < 10:\n",
    "            return ''\n",
    "        text = re.sub('[^A-Za-z0-9\\s+]+', '', text.strip())\n",
    "        if flag:\n",
    "            text = ' '.join(text.split())  \n",
    "            out = ngrams(text.strip().split(), n)\n",
    "            out = [' '.join(i) for i in out]\n",
    "            out = ','.join(out)\n",
    "        else:\n",
    "            vect = CountVectorizer(stop_words='english', ngram_range=(n, n))\n",
    "            vect.fit_transform([text.strip()])\n",
    "            out = ','.join(vect.get_feature_names_out())\n",
    "    except:\n",
    "        print(print(\">>\", text))\n",
    "   \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UNIGRAM'] = df.first_mail.progress_apply(lambda x: get_ngram_nltk(x, 1, False))\n",
    "df['BIGRAM'] = df.first_mail.progress_apply(lambda x: get_ngram_nltk(x, 2))\n",
    "df['TRIGRAM'] = df.first_mail.progress_apply(lambda x: get_ngram_nltk(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_wordss = ['email', 'dear', 'regards', 'thank',\n",
    "                 'kindly', 'thanks', 'hi', 'im', 'sir',\n",
    "                 'in the', 'of the', 'to the', 'for the', 'want to', 'you are', 'all rights reserved', 'if you',\n",
    "                 'and the', 'want to', 'on the',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worldcloud(column):\n",
    "    column = column[~column.isna()].tolist()\n",
    "    one_string = ','.join(column)\n",
    "    one_string = re.sub(' +|\\s+', ' ', one_string)\n",
    "    one_string = re.sub(' +|\\s+', ' ', one_string)\n",
    "    one_string = re.sub('\\s+,', ',', one_string)\n",
    "    one_string = re.sub(',\\s+', ',', one_string)\n",
    "    listword = one_string.split(',')\n",
    "    listword = [i for i in listword if i not in remove_wordss]\n",
    "    ngram_freq = Counter(listword)\n",
    "    word_cloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(ngram_freq)\n",
    "    return ngram_freq, word_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.Folder == 'Inbox') &\n",
    "         (df.is_from_external == 1) &\n",
    "         (df.is_english == 1) &\n",
    "         (df.is_arabic == 0) &\n",
    "         (df.is_first_in_conversation == 1) &\n",
    "         (df.SUBJECT_FLAG != 'MARKETING') &\n",
    "         (df.FROM_DOMAIN != 'hdfcbank.com')\n",
    "        ]\n",
    "\n",
    "ngramdf = []\n",
    "for col in ['UNIGRAM', 'BIGRAM', 'TRIGRAM']:\n",
    "    unigram_freq, word_cloud_unigram = get_worldcloud(df1[col])\n",
    "    unigram = pd.DataFrame(unigram_freq, index=['Count']).rename_axis(col).T.sort_values('Count', ascending=False)\n",
    "    unigram = unigram.reset_index().rename(columns={'index': col})\n",
    "    unigram.to_csv(f'{col}.csv', index=False)\n",
    "    ngramdf.append(unigram)\n",
    "    # Display the generated Word Cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(word_cloud_unigram)\n",
    "    plt.axis('off')\n",
    "    plt.suptitle(f'{col} Keywords', fontsize=16)\n",
    "    plt.savefig(f\"{col}.png\")\n",
    "    plt.show()\n",
    "\n",
    "ngram_df = pd.concat(ngramdf, axis=1)\n",
    "ngram_df.to_csv('ngram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['XDG_CACHE_HOME']='Z:\\AI_Models'\n",
    "from stormtrooper import ZeroShotClassifier\n",
    "\n",
    "labels = ['COMPLAINTS',\n",
    "          'SALES_REQUESTS',\n",
    "          'SERVICE_REQUESTS',\n",
    "          'APPRECIATIONS',\n",
    "          'SPAM',\n",
    "          'OTHER',\n",
    "          'FOLLOW_UP']\n",
    "\n",
    "model = ZeroShotClassifier(\"facebook/bart-large-mnli\").fit(None, labels)\n",
    "\n",
    "labels = ['COMPLAINTS',\n",
    "          'SALES_REQUESTS',\n",
    "          'SERVICE_REQUESTS',\n",
    "          'APPRECIATIONS',\n",
    "          'SPAM',\n",
    "          'OTHER',\n",
    "          'FOLLOW_UP']\n",
    "labels = sorted(labels)\n",
    "for i, j in enumerate(labels):\n",
    "    k = j.replace('_', \" \")\n",
    "    print(f\"## {i+1}.{k.title()}<a id='S{i}'></a>\")  # 1. Customer Request\n",
    "\n",
    "df1.to_excel('email_20231210.xlsx')\n",
    "\n",
    "model.set_output(transform='pandas')\n",
    "\n",
    "df1 = df[(df.Folder == 'Inbox') &\n",
    "         (df.is_from_external == 1) &\n",
    "         (df.is_english == 1) &\n",
    "         (df.is_arabic == 0) &\n",
    "         (df.is_first_in_conversation == 1) &\n",
    "         (df.SUBJECT_FLAG != 'MARKETING') &\n",
    "         (df.FROM_DOMAIN != 'hdfcbank.com')\n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
