{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QIB Email *Extract, Load, and Transform* Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Third-Party Imports\n",
    "import pypff # type: ignore\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Local Imports\n",
    "from src.config.config import Config\n",
    "from src.extract.pst_message_extractor import PstMessageExtractor\n",
    "from src.transform.message_parser import MessageParser, ParsedMessage\n",
    "from src.transform.message_enricher import MessageEnricher, EnrichedMessage\n",
    "from src.load.data_loader import DataLoader\n",
    "from src.database.database import Database\n",
    "from src.utils.data_exporter import DataExporter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger('chardet.charsetprober').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_json(\"config.json\")\n",
    "extractor = PstMessageExtractor(config.input_pst_path, config.chunk_size)\n",
    "message_parser = MessageParser()\n",
    "message_enricher = MessageEnricher()\n",
    "database = Database.from_credentials(username=config.db_user, password=config.db_password, host=config.db_host, database=config.db_name)\n",
    "loader = DataLoader(database)\n",
    "exporter = DataExporter(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Pipeline with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d57f5624d94f3cad4d5ff3c9cb38c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting messages:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:All tables have been dropped from the database.\n",
      "INFO:root:All tables have been created in the database.\n",
      "INFO:root:Starting ETL Pipeline\n",
      "INFO:langid.langid:initializing identifier\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "ERROR:root:Error getting value for key conversation_topic: pypff_message_get_conversation_topic: unable to retrieve conversation topic size. libuna_unicode_character_copy_from_utf16_stream: unsupported UTF-16 character. libuna_utf8_string_size_from_utf16_stream: unable to copy Unicode character from UTF-16 stream. libpff_mapi_value_get_data_as_utf8_string_size: unable to determine size of value data as UTF-8 string. libpff_record_entry_get_data_as_utf8_string_size_with_codepage: unable to determine size of value data as UTF-8 string. libpff_internal_item_get_entry_value_utf8_string_size: unable to retrieve UTF-8 string size. libpff_message_get_entry_value_utf8_string_size: unable to retrieve UTF-8 string size.\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 250 messages into the database\n",
      "INFO:root:Successfully loaded 39 messages into the database\n",
      "INFO:root:Finished ETL Pipeline in 1 minutes and 16 seconds\n"
     ]
    }
   ],
   "source": [
    "total_batches = extractor.get_total_batches(\"Inbox\")\n",
    "pbar = tqdm(total=total_batches, desc='Extracting messages')\n",
    "start_time = time.time()\n",
    "\n",
    "database.drop_all_tables()\n",
    "loader.create_tables()\n",
    "logging.info(\"Starting ETL Pipeline\")\n",
    "for message_batch in extractor.extract_messages(\"Inbox\"):\n",
    "    enriched_messages: List[EnrichedMessage] = []\n",
    "    \n",
    "    for pst_message in message_batch.messages:\n",
    "        provider_email_id = pst_message.provider_email_id\n",
    "        # logging.debug(f\"Processing message {provider_email_id}\")\n",
    "        try:\n",
    "            parsed_message: ParsedMessage = message_parser.parse(pst_message.message, provider_email_id, pst_message.folder_name)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            enriched_message: EnrichedMessage = message_enricher.enrich_message(parsed_message)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        else:\n",
    "            enriched_messages.append(enriched_message)\n",
    "\n",
    "    try:\n",
    "        loader.load(enriched_messages)\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"Error loading messages in batch {message_batch.batch_id}: {e}\")\n",
    "        continue\n",
    "    else:\n",
    "        logging.debug(f\"Loaded {len(enriched_messages)} messages in batch {message_batch.batch_id}\")\n",
    "\n",
    "    pbar.update(1)\n",
    "end_time = time.time()\n",
    "pbar.close()\n",
    "logging.info(f\"Finished ETL Pipeline in {int(end_time - start_time) // 60} minutes and {int(end_time - start_time) % 60} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Exported database to Excel\n"
     ]
    }
   ],
   "source": [
    "exporter.export_to_excel(\"./data/processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
