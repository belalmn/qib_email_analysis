{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QIB Email *Extract, Load, and Transform* Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import logging\n",
    "import time\n",
    "from typing import List\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "\n",
    "# Third-Party Imports\n",
    "import pypff # type: ignore\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Local Imports\n",
    "from src.config.config import Config\n",
    "from src.extract.message_extractor import PstMessageExtractor, MessageBatch, PstMessage\n",
    "from src.transform.message_parser import MessageParser, ParsedMessage\n",
    "from src.transform.message_enricher import MessageEnricher, EnrichedMessage\n",
    "from src.load.data_loader import DataLoader\n",
    "from src.database.database import Database\n",
    "from src.database.export_utils import DataExporter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger('chardet.charsetprober').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_json(\"config.json\")\n",
    "extractor = PstMessageExtractor(config.input_pst_path, config.chunk_size)\n",
    "message_parser = MessageParser()\n",
    "message_enricher = MessageEnricher()\n",
    "database = Database.from_credentials(username=config.db_user, password=config.db_password, host=config.db_host, database=config.db_name)\n",
    "loader = DataLoader(database)\n",
    "exporter = DataExporter(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Worker Function for Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message_batch(message_batch: MessageBatch):\n",
    "    parsed_messages = []\n",
    "    enriched_messages = []\n",
    "    loaded_count = 0\n",
    "\n",
    "    for pst_message in message_batch.messages:\n",
    "        try:\n",
    "            parsed_message = message_parser.parse(pst_message.message, pst_message.folder_name)\n",
    "            parsed_messages.append(parsed_message)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error parsing message: {e}\")\n",
    "            continue\n",
    "\n",
    "    for parsed_message in parsed_messages:\n",
    "        try:\n",
    "            enriched_message = message_enricher.enrich_message(parsed_message)\n",
    "            enriched_messages.append(enriched_message)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error enriching message: {e}\")\n",
    "            continue\n",
    "\n",
    "    for enriched_message in enriched_messages:\n",
    "        try:\n",
    "            loader.load(enriched_message)\n",
    "            loaded_count += 1\n",
    "        except SQLAlchemyError as e:\n",
    "            logging.error(f\"Error loading message {enriched_message.provider_email_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return loaded_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Pipeline with Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:All tables have been dropped from the database.\n",
      "INFO:root:All tables have been created in the database.\n",
      "INFO:root:Starting ETL Pipeline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f60846e834f1e8e62140d0b204bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing messages:   0%|          | 0/5039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'pypff.message' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mimap_unordered(process_message_batch, extractor\u001b[38;5;241m.\u001b[39mextract_messages(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInbox\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_messages, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing messages\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloaded_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/qib/lib/python3.11/multiprocessing/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/qib/lib/python3.11/multiprocessing/pool.py:540\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    542\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/qib/lib/python3.11/multiprocessing/connection.py:205\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/qib/lib/python3.11/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'pypff.message' object"
     ]
    }
   ],
   "source": [
    "total_messages = extractor.get_total_messages(\"Inbox\")\n",
    "start_time = time.time()\n",
    "\n",
    "database.drop_all_tables()\n",
    "loader.create_tables()\n",
    "logging.info(\"Starting ETL Pipeline\")\n",
    "\n",
    "with Pool(cpu_count()) as pool:\n",
    "    results = pool.imap_unordered(process_message_batch, extractor.extract_messages(\"Inbox\"))\n",
    "    \n",
    "    with tqdm(total=total_messages, desc='Processing messages') as pbar:\n",
    "        for loaded_count in results:\n",
    "            pbar.update(loaded_count)\n",
    "\n",
    "end_time = time.time()\n",
    "logging.info(f\"Finished ETL Pipeline in {int(end_time - start_time) // 60} minutes and {int(end_time - start_time) % 60} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter.export_to_excel(\"./data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter.export_schema('./data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
