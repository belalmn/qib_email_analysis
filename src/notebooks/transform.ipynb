{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline: Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.config.config import Config\n",
    "from src.database.chroma_manager import ChromaManager\n",
    "from src.database.database import Database\n",
    "from src.load.data_loader import DataLoader\n",
    "from src.transform.email_summary import summarize_messages\n",
    "from src.transform.llm_invoker import LLMInvoker\n",
    "from src.transform.message_classification import classify_categories\n",
    "from src.transform.product_classification import classify_products\n",
    "from src.transform.ner import extract_entities_from_messages\n",
    "from src.transform.spam_classification import (\n",
    "    classify_spam_messages_with_llm,\n",
    "    zero_shot_classify_spam_messages,\n",
    ")\n",
    "from src.transform.topic_modelling import TopicModellor\n",
    "from src.utils.checkpoint import DataFrameCheckpointer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "config = Config.from_json(\"../../config.json\")\n",
    "llm_invoker = LLMInvoker(model_name=\"phi3:3.8b-mini-4k-instruct-fp16\", use_ollama=config.use_ollama)\n",
    "database = Database.from_credentials(username=config.db_user, password=config.db_password, host=config.db_host, database=config.db_name)\n",
    "loader = DataLoader(database)\n",
    "                         \n",
    "DATA_DIR = '../../data'\n",
    "PST_DIR = config.pst_directory\n",
    "DATE = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "checkpointer = DataFrameCheckpointer(DATA_DIR + '/checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{DATA_DIR}/interim/preprocessed_messages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Quarterly, Monthly, and Weekly Sets of Messages from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most feature engineering tasks don't need to be run on all emails. The following feature engineering tasks are intended for customer oriented emails. We can safely disregard internal emails and outgoing emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df = df.loc[(df[\"is_internal\"] == False) & (df[\"from_address\"] != \"info@qib.com.qa\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further filter by removing spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam_df = classify_spam_messages_with_llm(message_df, llm_invoker)\n",
    "spam_df = zero_shot_classify_spam_messages(message_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer.save(\"spam_classification\", spam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df = message_df.merge(spam_df, on=\"message_id\")\n",
    "message_df = message_df.loc[message_df[\"is_spam\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer.save(\"spam_classified_messages\", message_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Sentence Transformer and ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = ChromaManager(\"message_embeddings\", model_name=config.embedding_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get or Create Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df = chroma.populate_embeddings(message_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer.save(\"message_embeddings\", message_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intent Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modellor = TopicModellor(message_df, llm_invoker)\n",
    "topic_df = topic_modellor.topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_to_describe = topic_df[topic_df[\"topic_id\"] != -1].groupby(\"topic_id\").filter(lambda x: len(x) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_descriptions = topic_modellor.get_topic_descriptions(topics_to_describe, llm_invoker)[[\"topic_id\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer.save(\"topic_descriptions\", topic_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df = topic_df[[\"message_id\", \"topic_id\"]].merge(message_df, on=\"message_id\")\n",
    "topics_df = topic_df.merge(topic_descriptions, on=\"topic_id\")[[\"topic_id\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = topic_modellor.get_topic_word_frequencies(topic_df)[[\"topic_id\", \"word\", \"frequency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer.save(\"topics\", topic_df)\n",
    "checkpointer.save(\"word_frequencies\", word_frequencies)\n",
    "checkpointer.save(\"topic_messages\", message_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Clusters, their Descriptions, and their Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = classify_categories(message_df)\n",
    "checkpointer.save(\"classification\", class_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = classify_products(message_df)\n",
    "checkpointer.save(\"products\", product_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = extract_entities_from_messages(message_df, llm_invoker)\n",
    "checkpointer.save(\"entities\", entities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Email Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = summarize_messages(message_df, llm_invoker)\n",
    "checkpointer.save(\"summaries\", summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate list-like columns into new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_address_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def split_addresses(addresses):\n",
    "        return addresses.split(\",\") if addresses else []\n",
    "\n",
    "    # Explode each address type into separate rows\n",
    "    from_df = pd.DataFrame({\n",
    "        \"message_id\": df[\"message_id\"],\n",
    "        \"address_type\": \"from\",\n",
    "        \"address\": df[\"from_address\"]\n",
    "    })\n",
    "\n",
    "    to_df = df[[\"message_id\", \"to_address\"]].assign(address_type=\"to\")\n",
    "    to_df = to_df.explode(\"to_address\").rename(columns={\"to_address\": \"address\"})\n",
    "\n",
    "    cc_df = df[[\"message_id\", \"cc_address\"]].assign(address_type=\"cc\")\n",
    "    cc_df = cc_df.explode(\"cc_address\").rename(columns={\"cc_address\": \"address\"})\n",
    "\n",
    "    bcc_df = df[[\"message_id\", \"bcc_address\"]].assign(address_type=\"bcc\")\n",
    "    bcc_df = bcc_df.explode(\"bcc_address\").rename(columns={\"bcc_address\": \"address\"})\n",
    "\n",
    "    # Combine all address types into a single dataframe\n",
    "    address_df = pd.concat([from_df, to_df, cc_df, bcc_df], ignore_index=True)\n",
    "\n",
    "    return address_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[[\"message_id\", \"references\"]].explode(\"references\").rename(columns={\"references\": \"reference_message_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[[\"message_id\", \"domain\"]].explode(\"domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df = create_address_df(message_df)\n",
    "reference_df = create_reference_df(message_df)\n",
    "domain_df = create_domain_df(message_df)\n",
    "\n",
    "checkpointer.save(\"addresses\", address_df)\n",
    "checkpointer.save(\"references\", reference_df)\n",
    "checkpointer.save(\"domains\", domain_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df.to_csv(config.output_directory + f\"/messages_{DATE}.csv\", index=False)\n",
    "address_df.to_csv(config.output_directory + f\"/addresses_{DATE}.csv\", index=False)\n",
    "reference_df.to_csv(config.output_directory + f\"/references_{DATE}.csv\", index=False)\n",
    "domain_df.to_csv(config.output_directory + f\"/domains_{DATE}.csv\", index=False)\n",
    "word_frequencies.to_csv(config.output_directory + f\"/word_frequencies_{DATE}.csv\", index=False)\n",
    "topics_df.to_csv(config.output_directory + f\"/topics_{DATE}.csv\", index=False)\n",
    "class_df.to_csv(config.output_directory + f\"/classification_{DATE}.csv\", index=False)\n",
    "product_df.to_csv(config.output_directory + f\"/products_{DATE}.csv\", index=False)\n",
    "entities_df.to_csv(config.output_directory + f\"/entities_{DATE}.csv\", index=False)\n",
    "summary_df.to_csv(config.output_directory + f\"/summaries_{DATE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.load_dataframe(message_df, \"messages\")\n",
    "loader.load_dataframe(address_df, \"addresses\")\n",
    "loader.load_dataframe(reference_df, \"references\")\n",
    "loader.load_dataframe(domain_df, \"domains\")\n",
    "loader.load_dataframe(word_frequencies, \"word_frequencies\")\n",
    "loader.load_dataframe(topics_df, \"topics\")\n",
    "loader.load_dataframe(class_df, \"classifications\")\n",
    "loader.load_dataframe(product_df, \"products\")\n",
    "loader.load_dataframe(entities_df, \"entities\")\n",
    "loader.load_dataframe(summary_df, \"summaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### message_df:\n",
    "    - message_id\n",
    "    - topic_id\n",
    "    - is_spam\n",
    "    - subject\n",
    "    - subject_prefix\n",
    "    - submit_time\n",
    "    - delivery_time\n",
    "    - html_body\n",
    "    - plain_text_body\n",
    "    - from_name\n",
    "    - previous_message_id\n",
    "    - first_in_thread\n",
    "    - num_previous_messages\n",
    "    - thread_id\n",
    "    - sender_domain\n",
    "    - is_internal\n",
    "    - clean_text\n",
    "    - response_time\n",
    "    - language\n",
    "\n",
    "### address_df:\n",
    "    - message_id\n",
    "    - address_type\n",
    "    - address\n",
    "\n",
    "### reference_df:\n",
    "    - message_id\n",
    "    - reference_message_id\n",
    "\n",
    "### domain_df:\n",
    "    - message_id\n",
    "    - domain\n",
    "    \n",
    "#### word_frequencies\n",
    "    - topic_id\n",
    "    - word\n",
    "    - frequency\n",
    "\n",
    "#### topics_df\n",
    "    - topic_id\n",
    "    - topic_description\n",
    "\n",
    "#### class_df\n",
    "    - message_id\n",
    "    - category\n",
    "\n",
    "#### product_df\n",
    "    - message_id\n",
    "    - product\n",
    "\n",
    "#### entities_df\n",
    "    - message_id\n",
    "    - entity_type\n",
    "    - entity_value\n",
    "\n",
    "#### summary_df\n",
    "    - message_id\n",
    "    - summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
